{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Predictions\n",
    "\n",
    "In this Notebook I made a model using XGBBoost introduced in https://www.kaggle.com/alexisbcook/xgboost, which results in top 40% accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 79) (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('./ames_housing_train.csv', index_col='Id')\n",
    "X_test = pd.read_csv('./ames_housing_test.csv', index_col='Id')\n",
    "\n",
    "# we set our target to be the log of the SalePrice\n",
    "X.SalePrice = np.log(X.SalePrice)\n",
    "\n",
    "# drop the row with NaN in 'Electrical'\n",
    "X = X[pd.notnull(X['Electrical'])]\n",
    "\n",
    "# create target vector\n",
    "y = X.SalePrice\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "print(X.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these columns will be dropped ['PoolQC', 'MiscFeature', 'Alley', 'GarageCars', 'PoolArea', 'MiscVal', 'Exterior1st', 'Exterior2nd']\n",
      "these columns will be replaced ['Fence', 'FireplaceQu', 'GarageCond', 'GarageQual', 'GarageType', 'GarageFinish', 'BsmtCond', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\n"
     ]
    }
   ],
   "source": [
    "#### What are the names of the columns with cardinality larger than 10?\n",
    "high_cardinality_cols = [cname for cname in X.columns if X[cname].nunique() >= 10 and \n",
    "                        X[cname].dtype == \"object\"]\n",
    "high_cardinality_cols.remove('Neighborhood')\n",
    "\n",
    "# Columns like 'PoolQC', 'MiscFeature', 'Alley', 'GarageQual', 'GarageCars', will be removed\n",
    "rem = ['PoolQC', 'MiscFeature', 'Alley', 'GarageCars', 'PoolArea', 'MiscVal']\n",
    "remove = rem + high_cardinality_cols\n",
    "print('these columns will be dropped', remove)\n",
    "\n",
    "replace = ['Fence', 'FireplaceQu', 'GarageCond', 'GarageQual', 'GarageType', 'GarageFinish', 'BsmtCond', 'BsmtQual', \n",
    "         'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\n",
    "print('these columns will be replaced', replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(data_X, to_rep, to_rem):\n",
    "    \n",
    "    # replace NaNs with No's\n",
    "    for i in to_rep:\n",
    "        data_X[i].fillna(\"No\", inplace = True)\n",
    "        \n",
    "    # some features can be label encoded\n",
    "    data_X.ExterQual.replace({\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1})\n",
    "    data_X.ExterCond.replace({\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1})\n",
    "    data_X.BsmtFinType1.replace({'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1, 'No':0})\n",
    "    data_X.BsmtFinType2.replace({'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1, 'No':0})\n",
    "    data_X.HeatingQC.replace({\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1})\n",
    "    data_X.KitchenQual.replace({\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1})\n",
    "    data_X.Functional.replace({\"Typ\":7, \"Min1\":6, \"Min2\":5, \"Mod\":4, \"Maj1\":3, \"Maj2\":2, \"Sev\":1, \"Sal\":0})\n",
    "    data_X.FireplaceQu.replace({\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1, \"No\":0})\n",
    "    data_X.GarageCond.replace({\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1, \"No\":0})\n",
    "    data_X.GarageQual.replace({\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1, \"No\":0})\n",
    "    data_X.BsmtQual.replace({\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1, \"No\":0})\n",
    "    data_X.BsmtCond.replace({\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1, \"No\":0})\n",
    "    \n",
    "    # fill the NaNs\n",
    "    data_X['LotFrontage'].fillna((data_X['LotFrontage'].median()), inplace=True)\n",
    "\n",
    "    LotArea_median = data_X['LotArea'].median()\n",
    "    func = lambda x: x['LotArea'] > 50000 and LotArea_median or x['LotArea']\n",
    "    data_X['LotArea'] = data_X.apply(func,axis=1).astype(float)\n",
    "    \n",
    "    LotFrontage_median = data_X['LotFrontage'].median()\n",
    "    func = lambda x: x['LotFrontage'] > 300 and LotFrontage_median or x['LotFrontage']\n",
    "    data_X['LotFrontage'] = data_X.apply(func,axis=1).astype(float)\n",
    "\n",
    "    GrLivArea_median = data_X['GrLivArea'].median()\n",
    "    func = lambda x: x['GrLivArea'] > 4000 and GrLivArea_median or x['GrLivArea']\n",
    "    data_X['GrLivArea'] = data_X.apply(func,axis=1).astype(float)\n",
    "    \n",
    "    data_X['MasVnrType'].fillna(\"None\", inplace = True)\n",
    "    data_X['GarageYrBlt'].fillna(data_X['GarageYrBlt'].median(), inplace = True)\n",
    "    data_X['MasVnrArea'].fillna(0, inplace = True)\n",
    "    \n",
    "    # drop the features we wanted to drop\n",
    "    data_X = data_X.drop(to_rem, axis=1)\n",
    "    \n",
    "    # define new features\n",
    "    data_X['Age'] = data_X['YrSold'] - data_X['YearBuilt']\n",
    "    data_X['AgeRemodel'] = data_X['YrSold'] - data_X['YearRemodAdd']\n",
    "    data_X['AgeGarage'] = data_X['YrSold'] - data_X['GarageYrBlt']\n",
    "    \n",
    "    # drop the features we used to create new ones\n",
    "    data_X = data_X.drop(['YrSold', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt'], axis=1)\n",
    "    \n",
    "    return data_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GridSearchCV we can use the complete training set. Splitting it into '_train' and '_validation' is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = transform_dataset(X, replace, remove)\n",
    "y_train = y\n",
    "X_test = transform_dataset(X_test, replace, remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the data (to shorten the code, we use pandas)\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:25:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# the inital model\n",
    "xg_reg = XGBRegressor()\n",
    "xg_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the submissions are evaluated on 'Root-Mean-Squared-Error (RMSE)' we need to introduce this loss function to train our model efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def my_custom_loss_func(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "rmse_scorer = make_scorer(my_custom_loss_func, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=1, gamma=0,\n",
       "                                    importance_type='gain', learning_rate=0.1,\n",
       "                                    max_delta_step=0, max_depth=3,\n",
       "                                    min_child_weight=1, missing=None,\n",
       "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                    objective='reg:linear', random_state=0,...\n",
       "                                    subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid={'colsample_bytree': [0.3, 0.4],\n",
       "                         'eta': [0.3, 0.2, 0.35], 'max_depth': range(3, 5),\n",
       "                         'min_child_weight': range(3, 5),\n",
       "                         'n_estimators': [800, 1000, 1200],\n",
       "                         'subsample': [1.0, 0.8, 0.9]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(my_custom_loss_func, greater_is_better=False),\n",
       "             verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "test_params = {'max_depth': range(3,5), 'min_child_weight':range(3,5), 'eta': [.3, .2, .35],\n",
    "               'subsample':[1.0, 0.8, 0.9], 'colsample_bytree':[0.3, 0.4], \n",
    "               'n_estimators':[800, 1000, 1200]}\n",
    "\n",
    "model = GridSearchCV(estimator = xg_reg, param_grid = test_params, cv = 5, n_jobs = 4, scoring = rmse_scorer)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.3, 'eta': 0.3, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 800, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "new_params = model.best_params_\n",
    "print(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the model automatically uses the best parameters\n",
    "preds_test = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': np.exp(preds_test)})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
